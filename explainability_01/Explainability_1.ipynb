{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability von Machine Learning Modellen am Beispiel eines Decision Tree und eines Multilayer Perceptron in Scikit-Learn\n",
    "Dieses Notebook ist Teil von <a href='https://datenverknoten.de/?p=212' target='_blank'>einem Artikel</a> auf www.datenverknoten.de.\n",
    "<br>Quelle des verwendeten Datensatzes: https://www.kaggle.com/lirilkumaramal/heart-stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenvorbereitung\n",
    "Zunächst werden die Daten geladen und die kategorischen Daten in numerische Werte überführt. In diesem Zusammenhang sei auch auf das Problem der Multikolinearität bei Dummy Variablen -> One Hot Encoding hingewiesen, die z.B. mit Pandas einfach erzeugt werden können hingewiesen (Erklärung z.B. hier: https://amanrai77.medium.com/dummy-variable-trap-9068c3f366fe). Doch auch der hier verwendete Ansatz birgt Tücken. Eine Diskussion findet sich z.B. hier: https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/. Dies soll aber nicht primärer Bestandteil sein, es wird der gegebene Ansatz als ideal angenommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Datei laden und die id Spalte löschen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_raw = pd.read_csv('rawdata/train_strokes.csv').drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder Objekt erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeilen mit na werden entfernt. Die kategorischen Daten werden mit dem Label Encoder in numerische Werte überführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_pre = stroke_raw.copy()\n",
    "stroke_pre = stroke_pre.dropna()\n",
    "stroke_pre['gender'] = labelencoder.fit_transform(stroke_pre['gender'])\n",
    "stroke_pre['ever_married'] = labelencoder.fit_transform(stroke_pre['ever_married'])\n",
    "stroke_pre['work_type'] = labelencoder.fit_transform(stroke_pre['work_type'])\n",
    "stroke_pre['Residence_type'] = labelencoder.fit_transform(stroke_pre['Residence_type'])\n",
    "stroke_pre['smoking_status'] = labelencoder.fit_transform(stroke_pre['smoking_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zu sehen, dass die Verteilung der beiden Klassen hochgradig unbalanciert ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(stroke_pre['stroke']).count(0)) # No stroke\n",
    "print(list(stroke_pre['stroke']).count(1)) # stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dieser Lambda-Funktion wird die kleinste Klasse gefunden und die Anzahl der Instanzen in dieser Klasse wird verwendet, um\n",
    "Instanzen aus der anderen Klasse zu samplen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_pre_2 = stroke_pre.groupby('stroke').apply(lambda x: x.sample(stroke_pre.stroke.value_counts().min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind beide Klassen stroke - Ja,Nein gleichmäßig oft vertreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(stroke_pre_2['stroke']).count(0)) # No stroke\n",
    "print(list(stroke_pre_2['stroke']).count(1)) # stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X enthält nun alle Variablen, die zur Vorhersage genutzt werden sollen. y ist die Variable, die vorhergesagt werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stroke_pre_2.drop(columns=['stroke'])\n",
    "y = stroke_pre_2['stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Trainings- und Testdaten werden erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Im ersten Schritt wird ein Entscheidungsbaum erstellt. Der Baum wird visualisert und auch als PDF ausgegeben. In jedem Knoten steht die Bedingung, die zur Entscheidung führt, ob die linke oder die rechte Kante verfolgt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Baumobjekt wird initialisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Baumobjekt wird auf die Daten gefittet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree_viz = clf_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit des Klassifikators wird anhand der Testdaten ermittelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe des Baumes hier im Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = plot_tree(clf_tree_viz, \n",
    "                   feature_names=X.columns,  \n",
    "                   class_names='stroke',\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe des Baumes in eine PDF Datei."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"dttree.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) -> Neuronales Netz\n",
    "Im zweiten Schritt wird ein vollverknüpftes neuronales Netz mit zwei hidden layers mit jeweils fünf Neuronen pro layer trainiert. Die Anzahl der maximalen backpropagation Durchläufe wird auf 2500 begrenzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Objekt wird erstellt. Zwei hidden layers mit jeweils fünf Neuronen, vollständig verknüpft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(random_state=1, max_iter=2500,hidden_layer_sizes=(5, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Trainingsdaten werden zum fitten verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit wird mit den Testdaten bestimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt keine Möglichkeit, die Entscheidungsfindung zu visualisieren. Zwar lassen sich die Gewichtungen der einzelnen Neuronen exportieren, doch diese sind nicht intuitiv zu interpretieren. Darum werden alle Kombinationen der Features erzeugt und es wird jedes mal das Netz mit dieser Kombination trainiert. Anhand der Genauigkeit wird dann abgelesen, welche Kombination die beste Vorhersage ergibt. So lässt sich zumindest erkennen, welche Features vom MLP als wichtig angesehen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion erzeugt alle möglichen Kombinationen der Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    xs = list(iterable)\n",
    "    return chain.from_iterable(combinations(xs,n) for n in range(len(xs)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird eine Liste aller möglichen Kombinationen mit der zuvor definierten Funktion erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_combinations = []\n",
    "for s in powerset(list(stroke_raw.drop(columns=['stroke']).columns)):\n",
    "    if(len(list(s))>0):\n",
    "        column_combinations.append(list(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Kombinationen werden in einem MLP Objekt genutzt. Die Genauigkeit und die jeweilige Kombination wird in einem DataFrame gesammelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame(columns=['Features','Featurelist','Accuracy'])\n",
    "\n",
    "for combination in column_combinations:\n",
    "    clf_mlp = MLPClassifier(random_state=1, max_iter=2500,hidden_layer_sizes=(5, 2))\n",
    "    clf_mlp.fit(X_train[combination], y_train)\n",
    "    score = clf_mlp.score(X_test[combination],y_test)\n",
    "    result_frame = result_frame.append({\\\n",
    "                                        'Features':len(combination),\\\n",
    "                                        'Featurelist':combination,\\\n",
    "                                        'Accuracy':score\n",
    "                                       },ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der DataFrame wird nach Genauigkeit sortiert. Die Featurekombination mit der höchsten Genauigkeit ist als diejenige anzunehmen, die am meisten zu einer Aussage über stroke - Ja,Nein beiträgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame.sort_values(by = 'Accuracy',ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An erster Stelle sind die Features Geschlecht, Alter, Bluthochdruck und Status Raucher (Ja,Nein) als Features zu erkennen, die die höchste Genauigkeit erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das Subset Problem\n",
    "Wird das Sampling mehrfach ausgeführt, zeigt sich, dass sowohl die höchste Genauigkeit als auch die zugehörige Featureliste variiert. Dies hängt mit dem Subset zusammen, das für die dominante Klasse gewählt wird. Um dies zu verdeutlichen, wird das oben beschriebene Beispiel zum Multilayer Perceptron mehrfach ausgeführt. Dabei wird sowohl jedes mal das Sampling als auch das Erstellen eines Trainings- und Testdatensatzes neu ausgeführt. Nur das Ergebnis mit der höchsten Genauigkeit wird in der Ergebnistabelle gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_resultframe = pd.DataFrame(columns = ['Run','Features','Featurelist','Accuracy'])\n",
    "\n",
    "for i in range(0,25):\n",
    "    print(\"Durchlauf: \"+str(i))\n",
    "    stroke_pre_2 = stroke_pre.groupby('stroke').apply(lambda x: x.sample(stroke_pre.stroke.value_counts().min()))\n",
    "    \n",
    "    X = stroke_pre_2.drop(columns=['stroke'])\n",
    "    y = stroke_pre_2['stroke']\n",
    "    # Diesmal wird das Trainings- und Testset ohne random_state erstellt, sodass die Wahl der Instanzen variiert. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    \n",
    "    clf_mlp = MLPClassifier(random_state=1, max_iter=2500,hidden_layer_sizes=(5, 2))\n",
    "    _ = clf_mlp.fit(X_train, y_train)\n",
    "    \n",
    "    result_frame = pd.DataFrame(columns=['Features','Featurelist','Accuracy'])\n",
    "\n",
    "    # Die Kombinationen wurden bereits erstellt und bleiben bestehen.\n",
    "    for combination in column_combinations:\n",
    "        clf_mlp = MLPClassifier(random_state=1, max_iter=2500,hidden_layer_sizes=(5, 2))\n",
    "        clf_mlp.fit(X_train[combination], y_train)\n",
    "        score = clf_mlp.score(X_test[combination],y_test)\n",
    "        result_frame = result_frame.append({\\\n",
    "                                            'Features':len(combination),\\\n",
    "                                            'Featurelist':combination,\\\n",
    "                                            'Accuracy':score\n",
    "                                           },ignore_index=True)\n",
    "    \n",
    "    # Die Ergebnisse werden im overall_resultframe gespeichert.\n",
    "    result_frame.sort_values(by = 'Accuracy',ascending = False, inplace = True)\n",
    "    best = result_frame.head(1).to_dict(orient='records')\n",
    "    best[0]['Run'] = i\n",
    "    overall_resultframe = overall_resultframe.append(best[0],ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allein in den ersten zehn Durchläufen lässt sich erkennen, dass die ausgewählten Features und die Genauigkeit bei unterschiedlicher Zusammensetzung des Trainings- und Testdatensatzes schwanken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_resultframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
